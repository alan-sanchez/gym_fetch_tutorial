{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stable-baselines3.readthedocs.io/en/master/guide/rl.html\n",
    "# https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html#a-taxonomy-of-rl-algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in /home/alan/.local/lib/python3.8/site-packages (2.1.0)\n",
      "Requirement already satisfied: pandas in /home/alan/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (2.0.3)\n",
      "Requirement already satisfied: cloudpickle in /home/alan/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (2.2.1)\n",
      "Requirement already satisfied: torch>=1.13 in /home/alan/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (2.0.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/alan/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (1.23.5)\n",
      "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (from stable-baselines3[extra]) (3.1.2)\n",
      "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /home/alan/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (0.29.1)\n",
      "Requirement already satisfied: shimmy[atari]~=1.1.0; extra == \"extra\" in /home/alan/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (1.1.0)\n",
      "Requirement already satisfied: rich; extra == \"extra\" in /home/alan/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (13.5.2)\n",
      "Requirement already satisfied: pygame; extra == \"extra\" in /home/alan/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (2.5.1)\n",
      "Requirement already satisfied: opencv-python; extra == \"extra\" in /home/alan/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (4.8.0.76)\n",
      "Requirement already satisfied: pillow; extra == \"extra\" in /home/alan/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (10.0.0)\n",
      "Requirement already satisfied: tqdm; extra == \"extra\" in /home/alan/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (4.66.1)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.6.1; extra == \"extra\" in /home/alan/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: psutil; extra == \"extra\" in /usr/lib/python3/dist-packages (from stable-baselines3[extra]) (5.5.1)\n",
      "Requirement already satisfied: tensorboard>=2.9.1; extra == \"extra\" in /home/alan/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (2.14.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/alan/.local/lib/python3.8/site-packages (from pandas->stable-baselines3[extra]) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/alan/.local/lib/python3.8/site-packages (from pandas->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/alan/.local/lib/python3.8/site-packages (from pandas->stable-baselines3[extra]) (2023.3.post1)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/alan/.local/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3[extra]) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/alan/.local/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3[extra]) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/alan/.local/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3[extra]) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/alan/.local/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3[extra]) (11.7.4.91)\n",
      "Requirement already satisfied: triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/alan/.local/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3[extra]) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/alan/.local/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3[extra]) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/alan/.local/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3[extra]) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/alan/.local/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3[extra]) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/alan/.local/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3[extra]) (11.7.91)\n",
      "Requirement already satisfied: sympy in /home/alan/.local/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3[extra]) (1.12)\n",
      "Requirement already satisfied: filelock in /home/alan/.local/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3[extra]) (3.12.3)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/alan/.local/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3[extra]) (11.7.101)\n",
      "Requirement already satisfied: networkx in /home/alan/.local/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3[extra]) (3.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/alan/.local/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3[extra]) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/alan/.local/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3[extra]) (10.2.10.91)\n",
      "Requirement already satisfied: typing-extensions in /home/alan/.local/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3[extra]) (4.7.1)\n",
      "Requirement already satisfied: jinja2 in /home/alan/.local/lib/python3.8/site-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/alan/.local/lib/python3.8/site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0; python_version < \"3.10\" in /home/alan/.local/lib/python3.8/site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.11.4)\n",
      "Requirement already satisfied: ale-py~=0.8.1; extra == \"atari\" in /home/alan/.local/lib/python3.8/site-packages (from shimmy[atari]~=1.1.0; extra == \"extra\"->stable-baselines3[extra]) (0.8.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/alan/.local/lib/python3.8/site-packages (from rich; extra == \"extra\"->stable-baselines3[extra]) (2.16.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/alan/.local/lib/python3.8/site-packages (from rich; extra == \"extra\"->stable-baselines3[extra]) (3.0.0)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /home/alan/.local/lib/python3.8/site-packages (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (5.7.1)\n",
      "Requirement already satisfied: requests in /home/alan/.local/lib/python3.8/site-packages (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2.31.0)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (7.0)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license; extra == \"accept-rom-license\" in /home/alan/.local/lib/python3.8/site-packages (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/alan/.local/lib/python3.8/site-packages (from tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (1.57.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/alan/.local/lib/python3.8/site-packages (from tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (0.7.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (45.2.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/alan/.local/lib/python3.8/site-packages (from tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/alan/.local/lib/python3.8/site-packages (from tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (2.3.7)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (0.34.2)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /home/alan/.local/lib/python3.8/site-packages (from tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (4.24.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/alan/.local/lib/python3.8/site-packages (from tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (1.4.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/alan/.local/lib/python3.8/site-packages (from tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (2.22.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/alan/.local/lib/python3.8/site-packages (from tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (3.4.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->stable-baselines3[extra]) (1.14.0)\n",
      "Requirement already satisfied: lit in /home/alan/.local/lib/python3.8/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.13->stable-baselines3[extra]) (16.0.6)\n",
      "Requirement already satisfied: cmake in /home/alan/.local/lib/python3.8/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.13->stable-baselines3[extra]) (3.27.4.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/alan/.local/lib/python3.8/site-packages (from sympy->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/alan/.local/lib/python3.8/site-packages (from jinja2->torch>=1.13->stable-baselines3[extra]) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata>=4.8.0; python_version < \"3.10\"->gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/alan/.local/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich; extra == \"extra\"->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (1.25.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/alan/.local/lib/python3.8/site-packages (from requests->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (3.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/alan/.local/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (0.2.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/alan/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (5.3.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/alan/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (4.9)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (0.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in /home/alan/.local/lib/python3.8/site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/alan/.local/lib/python3.8/site-packages (from gymnasium) (1.23.5)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/alan/.local/lib/python3.8/site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/alan/.local/lib/python3.8/site-packages (from gymnasium) (4.7.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/alan/.local/lib/python3.8/site-packages (from gymnasium) (2.2.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0; python_version < \"3.10\" in /home/alan/.local/lib/python3.8/site-packages (from gymnasium) (4.11.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata>=4.8.0; python_version < \"3.10\"->gymnasium) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /home/alan/.local/lib/python3.8/site-packages (2.14.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/alan/.local/lib/python3.8/site-packages (from tensorboard) (3.4.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/alan/.local/lib/python3.8/site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/alan/.local/lib/python3.8/site-packages (from tensorboard) (1.23.5)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard) (45.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/alan/.local/lib/python3.8/site-packages (from tensorboard) (0.7.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard) (0.34.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/alan/.local/lib/python3.8/site-packages (from tensorboard) (2.22.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/alan/.local/lib/python3.8/site-packages (from tensorboard) (1.57.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/alan/.local/lib/python3.8/site-packages (from tensorboard) (2.31.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/alan/.local/lib/python3.8/site-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /home/alan/.local/lib/python3.8/site-packages (from tensorboard) (4.24.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/alan/.local/lib/python3.8/site-packages (from tensorboard) (2.3.7)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/alan/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard) (4.11.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/alan/.local/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.14.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/alan/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/alan/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/alan/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/alan/.local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard) (1.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard) (0.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = \"CartPole-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an environment previously registered with gymnasium.register() or a EnvSpec.\n",
    "env = gym.make(environment_name)\n",
    "#gym.make??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.03256245, -0.02750515, -0.04948962,  0.02764346], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resets the environment to the initial state, required before calling step. \n",
    "# Returns the first agent observation for an episode and information, i.e. metrics, debug info.\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This method defines how many discrete/actions there are. \n",
    "# The Space object corresponding to valid actions, all valid actions should be contained within the space.\n",
    "env.action_space\n",
    "# env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the method that allows you to view the observation space\n",
    "env.observation_space\n",
    "# env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run for loop of enivonrment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closes the environment, important when external software is used, i.e. pygame for rendering, databases\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name,render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:19.0\n",
      "Episode:2 Score:39.0\n",
      "Episode:3 Score:32.0\n",
      "Episode:4 Score:17.0\n",
      "Episode:5 Score:34.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info, __ = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding The Environment\n",
    "https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-push cart to left, 1-push cart to the right\n",
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [cart position, cart velocity, pole angle, pole angular velocity]\n",
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train an RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make your directories first\n",
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(environment_name)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO('MlpPolicy', env, verbose = 1, tensorboard_log=log_path)\n",
    "# PPO??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/Logs/PPO_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1526 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1084        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008796491 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | -0.0123     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.83        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 54.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1014        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010288827 |\n",
      "|    clip_fraction        | 0.0714      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.664      |\n",
      "|    explained_variance   | 0.0732      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    value_loss           | 37          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 982         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008391992 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.629      |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    value_loss           | 48.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 962         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008026104 |\n",
      "|    clip_fraction        | 0.0768      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.608      |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    value_loss           | 56.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 951         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009089574 |\n",
      "|    clip_fraction        | 0.0755      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.581      |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 64.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 946         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009797446 |\n",
      "|    clip_fraction        | 0.0887      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.577      |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.63        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00967    |\n",
      "|    value_loss           | 47.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 935        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00512814 |\n",
      "|    clip_fraction        | 0.0319     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.55      |\n",
      "|    explained_variance   | 0.561      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 21.4       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.00852   |\n",
      "|    value_loss           | 59.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 933          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071567064 |\n",
      "|    clip_fraction        | 0.0727       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.564       |\n",
      "|    explained_variance   | 0.822        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.99         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    value_loss           | 31.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 917         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008423029 |\n",
      "|    clip_fraction        | 0.0885      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.574      |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.79        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00945    |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7fddd1298610>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save and Reload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_path = os.path.join('Training', 'Saved Models', 'PPO_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PPO_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(PPO_path, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500.0, 0.0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(environment_name,render_mode=\"human\")\n",
    "env = DummyVecEnv([lambda: env])\n",
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info [{'TimeLimit.truncated': True, 'terminal_observation': array([-0.00969358,  0.36210534,  0.10621299, -0.40715772], dtype=float32)}]\n",
      "reward 500.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(environment_name,render_mode=\"human\")\n",
    "env = DummyVecEnv([lambda: env])\n",
    "obs = env.reset()\n",
    "score = 0\n",
    "while True:\n",
    "    action, _states = model.predict(obs) #NOW USING MODEL HERE!!\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    env.render()\n",
    "    score += reward\n",
    "    if done: \n",
    "        print('info', info)\n",
    "        print('reward', score)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing the model methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model method api\n",
    "model.predict??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03617643, -0.01765439,  0.03399159, -0.02785905]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "action, _states = model.predict(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.03582334,  0.17696403,  0.03343441, -0.30962643]],\n",
       "       dtype=float32),\n",
       " array([1.], dtype=float32),\n",
       " array([False]),\n",
       " [{'TimeLimit.truncated': False}])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Viewing Logs in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log_path = os.path.join('Training', 'Logs', 'PPO_1')\n",
    "# training_log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "/home/alan/.local/lib/python3.8/site-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.33' not found (required by /home/alan/.local/lib/python3.8/site-packages/tensorboard_data_server/bin/server)\n",
      "/home/alan/.local/lib/python3.8/site-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.34' not found (required by /home/alan/.local/lib/python3.8/site-packages/tensorboard_data_server/bin/server)\n",
      "/home/alan/.local/lib/python3.8/site-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found (required by /home/alan/.local/lib/python3.8/site-packages/tensorboard_data_server/bin/server)\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.14.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir={training_log_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Adding a callback to the training Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training', 'Saved Models')\n",
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name) #,render_mode=\"human\")\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StopTrainingOnRewardThreshold??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold=190, verbose=1)\n",
    "eval_callback = EvalCallback(env, \n",
    "                             callback_on_new_best=stop_callback, \n",
    "                             eval_freq=10000, \n",
    "                             best_model_save_path=save_path, \n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', env, verbose = 1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/Logs/PPO_5\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1404 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1051        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009287951 |\n",
      "|    clip_fraction        | 0.0954      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | 0.00997     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.98        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 49.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 989         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010044297 |\n",
      "|    clip_fraction        | 0.0677      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.671      |\n",
      "|    explained_variance   | 0.0682      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    value_loss           | 36.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 942          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075557176 |\n",
      "|    clip_fraction        | 0.08         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.638       |\n",
      "|    explained_variance   | 0.19         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 23.5         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0172      |\n",
      "|    value_loss           | 58.9         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=333.00 +/- 153.44\n",
      "Episode length: 333.00 +/- 153.44\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 333          |\n",
      "|    mean_reward          | 333          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065600732 |\n",
      "|    clip_fraction        | 0.0553       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.613       |\n",
      "|    explained_variance   | 0.25         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 27.5         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0146      |\n",
      "|    value_loss           | 63.9         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "Stopping training because the mean reward 333.00  is above the threshold 190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7fddd11eacd0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join('Training', 'Saved Models', 'best_model')\n",
    "model = PPO.load(model_path, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360.65, 124.40027130195494)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=20, render=False)\n",
    "# evaluate_policy??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Changing Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_arch=[dict(pi=[128, 128, 128, 128], vf=[128, 128, 128, 128])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO('MlpPolicy', env, verbose = 1, policy_kwargs={'net_arch': net_arch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Using an Alternate Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN('MlpPolicy', env, verbose = 1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_path = os.path.join('Training', 'Saved Models', 'DQN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(dqn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN.load(dqn_path, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
